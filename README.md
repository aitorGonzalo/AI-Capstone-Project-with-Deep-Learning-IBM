# ðŸŒ AI CAPSTONE PROJECT â€” DEEP LEARNING FOR SATELLITE IMAGE CLASSIFICATION  

## ðŸ§  OVERVIEW  

This **AI Capstone Project** is an exciting hands-on journey into **Deep Learning for Image Classification**, specifically applied to **satellite imagery**.  

Imagine you're a **Data Scientist** for a fertilizer company aiming to expand into new territory. Your mission is to build **AI models** that automatically classify images into **AGRICULTURAL** and **NON-AGRICULTURAL** land.  

This automation saves time and effort compared to manual classification and helps the company design efficient strategies.  

---

## ðŸš€ PROJECT STRUCTURE  

The project was divided into **FOUR MODULES**, each one increasing in complexity â€” from basic data handling to advanced neural network architectures and Vision Transformers (ViTs).  

Dataset structure:  

- `class_0_non_agri/` â†’ Non-Agricultural Land  
- `class_1_agri/` â†’ Agricultural Land  

The objective: **Binary Classification** â€” determine whether an image shows agricultural or non-agricultural land.  

All experiments were conducted using **Jupyter Notebooks** for interactivity and visualization.  

---

## ðŸ“š MODULE BREAKDOWN  

### ðŸ§© MODULE 1: DATA PREPARATION AND EXPLORATION  

The foundation of any AI project is **data**.  

- Loaded and explored satellite images efficiently.  
- Implemented **lazy loading** for optimal memory management.  
- Prepared **balanced datasets** (equal agri and non-agri samples).  
- Applied **image preprocessing** and **augmentation** (resizing to 64Ã—64 pixels).  

ðŸ” **Outcome:** A clean, balanced, and memory-efficient dataset ready for deep learning.  

---

### âš™ï¸ MODULE 2: BUILDING AND COMPARING BASIC CLASSIFIERS  

This module introduced **Convolutional Neural Networks (CNNs)** â€” the workhorses of image AI.  

#### âœ… KERAS IMPLEMENTATION  

Keras made it simple to:  
- Define **convolutional**, **pooling**, and **dense** layers.  
- Use the **Adam** optimizer and **binary cross-entropy** loss.  
- Evaluate using **accuracy** and **confusion matrices**.  

Training involved DataLoaders, optimizers, and mini-batch iteration loops.

ðŸ“Š Result:

Both models achieved >95% accuracy.

Keras = faster prototyping.

PyTorch = greater flexibility and debugging control.

### ðŸ§¬ MODULE 3: ADVANCED MODELS WITH VISION TRANSFORMERS (VITs)

A leap forward into Vision Transformers (ViTs), inspired by transformer architectures used in NLP models like GPT.

ViTs treat images as sequences of patches, applying self-attention to learn global relationships.

Implemented using Keras layers such as:
